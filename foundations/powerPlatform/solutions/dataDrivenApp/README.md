# Data-driven Application

Dynamic data-driven application systems (DDDAS) is a modern application development paradigm with the objective to dynamically incorporate diverse datapoints and measurements to influence the execution model of the system. Datapoints and insights from historical data collections are integrated into a real-time system and combined with the context in form of online data to allow more effective and accurate results, responses, experiences, or decisions. In some scenarios, states cannot be directly measured. As a result, estimations and data assimilations are required. DDDAS ultimately allows to create a dynamic feedback loop which can be used to further enhance the execution model or enhance capabilities of a system.

New capabilities can be driven by new science and technology capabilities and can be related to application modelling approaches, algorithm developments (mathematical and statistical algorithms), systems software & instrumentation methods among others. Today, data science and smart BI solutions can be seen as the main driver of DDDAS, hence we will focus on this topic in this article.

This article will look at DDDAS from a business application context using Microsoft Power Platform as an application framework and will illustrate architectures that can be used to design data-driven applications in combination with other features of the Microsoft Power Platform or other Microsoft technologies. Two different design patterns will be showcased which serve different levels of requirements and use cases.

## Designing a Data-driven Application on the Microsoft Power Platform

The architecture diagram below illustrates the two design patterns (A) and (B), which will be further discussed below:

![Data Driven App](./images/DataDrivenApp.png)

## (A) Data-driven Application using Microsoft Power Platform

Power Platform includes a rich set of tools and features to enhance and add capabilities to your business processes. Power Platform Canvas apps, model apps, portal apps, Dynamics 365 (D365) apps or Power Automate flows can be used in combination with Dataverse to collect data and build a historical dataset. The data can be further enriched by integrating additional datasets using Power Query.

The data residing in Dataverse can then be used to train and host data science models within power platform using AI Builder. Eventually, these data science models can enhance the users experience, allow for automated or more informed decisions, and provide more accurate results. To make use of AI Builder, an AI Builder capacity add-on needs to be purchased for the existing Power Apps or Power Automate licenses. When purchasing the capacity, users need to estimate how much capacity will be required. Once the add-on has been purchased, the capacity needs to be allocated to the Power Platform environment where AI Builder will be used. More details about Licensing can be found [here](https://docs.microsoft.com/en-us/ai-builder/administer-licensing).

Once AI Builder capacity has been allocated to the Environment, users can select from a range of model types and categories. There are two types of models in AI Builder: *Prebuilt* and *Custom*. The majority of models is prebuilt and can be added to the application without requiring the user to select data or train and host the model. This simplifies the management overhead and is sufficient for many scenarios, but also means that the models cannot be tailored to the specific use case and data of the application. On the other hand, for custom models users are required to select a historical dataset or provide data samples to finetune the model (transfer learning). Once, the training was successful, the model can be used in Power Applications or in Power Automate. The provided capabilities by AI Builder are very similar to the Cognitive Services that are available on the Azure Platform today. However, in Power Platform these services are much more easily accessible and can also be consumed by business users.

Before adding machine learning capabilities to a Power App, it may also be sufficient to provide simple reporting capabilities to provide decision makers with insights that allow for more informed and data-driven conclusions. Power BI is the recommended tool for such requirements. Power BI can be connected to Dataverse to create Power BI Datasets. If additional data processing is required, users can also leverage Power Query to cleanse and process the data. Once the data is in the right format and shape, reports can be created on top of the Power BI Dataset(s). These can then be shared with users across an organization.

## (B) Data-driven Application using Microsoft Power Platform and Microsoft Azure

For certain use cases, the capabilities provided by AI Builder may be too generic or not sufficient. To overcome these limitations and be able to build more sophisticated solutions for specific application scenarios, it is recommended for customers to leverage the Azure platform and the rich ecosystem of services.
For this design approach it is recommended to create a Data Product environment within the Azure data platform consisting of an Azure Synapse Analytics workspace, an Azure Machine Learning workspace, a Key Vault and potentially a set of Cognitive Services or Azure Search to pre-process and enrich the data. Next, it is recommended to use Azure Synapse Link for Dataverse for integrating the data assets and entities from Dataverse into an ADLS Gen2 Filesystem/Container and create the table metadata in a Lake Database in Synapse. Once the data has landed in Azure, data engineers and data scientists can use Spark pools in Azure Synapse to efficiently pre-process and cleanse the data according to their requirements and then use Azure Machine Learning in combination with Cognitive Services and Azure Search to develop, train, log and register custom machine learning models.

Depending on the scenario developers may want to use the Machine Learning model itself in the Power Platform application or just want to use data and predictions that were created as part of a batch scoring process in Azure Machine Learning.
If the machine learning model itself should be used for real-time scoring scenarios within the Power Platform Environment, data scientists can take their custom model from Azure Machine Learning and register it in the Power Platform AI Builder. This feature is still in preview and more details can be found [here](https://docs.microsoft.com/en-us/ai-builder/byo-model). If data and predictions should be used in a Power Platform environment, it is recommended to use Power Query to securely integrate the data into Dataverse and the transactional system using a [virtual network data gateway](https://docs.microsoft.com/en-us/data-integration/vnet/overview). Schedules can be used if the data needs to be updated frequently.

In some scenarios, it may be required to integrate the data into the Azure platform first before loading it into Power BI. This might be the case if more complicated data processing is required before loading the data into Power BI. Again, Power Query is recommended to be used to securely load the data assets from an Azure datastore such as ADLS Gen2 and potentially apply additional transformations, if required. Once the data is loaded as a Power BI dataset and data is in the right shape and format reports and dashboards can be created and published and finally shared with users across an organization.
